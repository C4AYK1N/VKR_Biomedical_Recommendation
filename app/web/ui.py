"""
Ð’ÐµÐ±-Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° Streamlit.
ÐÐ²Ñ‚Ð¾Ñ€: Ð§Ð°Ð¹ÐºÐ¸Ð½ Ð’Ð¸Ñ‚Ð°Ð»Ð¸Ð¹ Ð¤ÐµÐ´Ð¾Ñ€Ð¾Ð²Ð¸Ñ‡
Ð¢ÐµÐ¼Ð° Ð’ÐšÐ : Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð±Ð¸Ð¾Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
"""

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sys
import os
import warnings
import json
from datetime import datetime
import pickle
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ
warnings.filterwarnings('ignore')

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ðº ÐºÐ¾Ñ€Ð½ÐµÐ²Ð¾Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
try:
    from app.core.data_loader import BiomedicalDataLoader
    from app.core.feature_engineer import ECGFeatureEngineer
    from app.core.model_loader import ModelLoader
    from app.services.training_service import TrainingService
    from app.services.prediction_service import PredictionService
    from utils.config import Config
except ImportError:
    # Ð”Ð»Ñ ÑÐ»ÑƒÑ‡Ð°Ñ, ÐµÑÐ»Ð¸ Ð¼Ð¾Ð´ÑƒÐ»Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹, ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ¸
    st.warning("âš ï¸ ÐÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð´ÑƒÐ»Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹.")
    
    class Config:
        SAMPLING_RATE = 360
        SEQUENCE_LENGTH = 360
        RANDOM_STATE = 42
        TEST_SIZE = 0.2
        VALIDATION_SIZE = 0.1
        ARRHYTHMIA_CLASSES = {
            0: "ÐÐ¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð¸Ñ‚Ð¼",
            1: "ÐÐ¿Ð½Ð¾Ñ", 
            2: "Ð¤Ð¸Ð±Ñ€Ð¸Ð»Ð»ÑÑ†Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑÐµÑ€Ð´Ð¸Ð¹",
            3: "Ð¨ÑƒÐ¼",
            4: "Ð”Ñ€ÑƒÐ³Ð°Ñ Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ"
        }
    
    class BiomedicalDataLoader:
        def download_dataset(self):
            return self._create_simulated_data()
        
        def _create_simulated_data(self):
            np.random.seed(42)
            n_samples = 5000
            n_features = 360
            X = np.random.randn(n_samples, n_features)
            y = np.random.randint(0, 5, n_samples)
            return X, y
        
        def split_data(self, X, y):
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            X_train, X_val, y_train, y_val = train_test_split(
                X_train, y_train, test_size=0.1, random_state=42
            )
            return X_train, X_val, X_test, y_train, y_val, y_test

class BiomedicalApp:
    """ÐšÐ»Ð°ÑÑ Ð²ÐµÐ±-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð­ÐšÐ“."""
    
    def __init__(self):
        self.config = Config()
        self.setup_page()
        self.initialize_services()
        self.ensure_directories()
        
    def setup_page(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Streamlit."""
        st.set_page_config(
            page_title="Ð˜Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð­ÐšÐ“",
            page_icon="â¤ï¸",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        st.title("â¤ï¸ Ð˜Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð±Ð¸Ð¾Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…")
        st.markdown("---")
        
    def ensure_directories(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ñ… Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹."""
        directories = ["models", "data", "results", "logs"]
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def initialize_services(self):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²."""
        if 'initialized' not in st.session_state:
            try:
                self.data_loader = BiomedicalDataLoader()
                self.feature_engineer = ECGFeatureEngineer()
                self.model_loader = ModelLoader()
                self.training_service = TrainingService(self.model_loader, self.feature_engineer)
                self.prediction_service = PredictionService(
                    self.model_loader, self.feature_engineer, self.data_loader
                )
            except:
                # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ¸ Ð´Ð»Ñ ÑÐµÑ€Ð²Ð¸ÑÐ¾Ð²
                self.data_loader = BiomedicalDataLoader()
                self.feature_engineer = None
                self.model_loader = None
                self.training_service = None
                self.prediction_service = None
            
            # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐµÑÑÐ¸Ð¸
            st.session_state.initialized = True
            st.session_state.models_trained = False
            st.session_state.data_loaded = False
            st.session_state.current_tab = "data_analysis"
            st.session_state.metrics_history = []
    
    def render_sidebar(self):
        """ÐžÑ‚Ñ€Ð¸ÑÐ¾Ð²ÐºÐ° Ð±Ð¾ÐºÐ¾Ð²Ð¾Ð¹ Ð¿Ð°Ð½ÐµÐ»Ð¸."""
        with st.sidebar:
            st.title("ðŸ§­ ÐÐ°Ð²Ð¸Ð³Ð°Ñ†Ð¸Ñ")
            
            tabs = {
                "ðŸ“Š ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…": "data_analysis",
                "ðŸ¤– ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹": "model_training", 
                "ðŸ” ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ": "prediction",
                "ðŸ“ˆ Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹": "model_comparison",
                "ðŸ“‹ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²": "experiment_history",
                "â„¹ï¸ Ðž Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ": "about"
            }
            
            selected_tab = st.radio(
                "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»:", 
                list(tabs.keys()),
                index=list(tabs.values()).index(st.session_state.current_tab) 
                if st.session_state.current_tab in tabs.values() else 0
            )
            st.session_state.current_tab = tabs[selected_tab]
            
            st.markdown("---")
            
            # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
            st.subheader("ðŸ“Š Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹")
            
            status_items = []
            if st.session_state.get('data_loaded', False):
                status_items.append("âœ… Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹")
            else:
                status_items.append("âŒ Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹")
            
            if st.session_state.get('rf_model', None):
                status_items.append("âœ… RF Ð¾Ð±ÑƒÑ‡ÐµÐ½")
            
            if st.session_state.get('cnn_model', None):
                status_items.append("âœ… CNN Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð°")
            
            for item in status_items:
                st.write(f"â€¢ {item}")
            
            st.markdown("---")
            
            # Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ
            st.subheader("âš¡ Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ðŸ”„ Ð¡Ð±Ñ€Ð¾Ñ", help="Ð¡Ð±Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ"):
                    keys_to_delete = [k for k in st.session_state.keys() 
                                    if k not in ['initialized', 'current_tab']]
                    for key in keys_to_delete:
                        del st.session_state[key]
                    st.rerun()
            
            with col2:
                if st.button("ðŸ’¾ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚", help="Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"):
                    self.export_results()
            
            st.markdown("---")
            
            # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ
            st.caption(f"**Ð’ÐµÑ€ÑÐ¸Ñ:** 1.0.0")
            st.caption(f"**Ð”Ð°Ñ‚Ð°:** {datetime.now().strftime('%d.%m.%Y')}")
            st.caption("Â© Ð§Ð°Ð¹ÐºÐ¸Ð½ Ð’.Ð¤., 2025")
    
    def render_data_analysis_tab(self):
        """Ð’ÐºÐ»Ð°Ð´ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…."""
        st.header("ðŸ“Š ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð­ÐšÐ“")
        
        # Ð’Ñ‹Ð±Ð¾Ñ€ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
        data_source = st.radio(
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…:",
            ["Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ", "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ñ„Ð°Ð¹Ð»"],
            horizontal=True,
            key="data_source_select"
        )
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            if data_source == "Ð¡Ð¸Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ":
                st.subheader("ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸")
                
                n_samples = st.slider(
                    "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð²:", 
                    min_value=1000, 
                    max_value=10000, 
                    value=5000, 
                    step=1000
                )
                
                if st.button("ðŸŽ² Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ", type="primary"):
                    with st.spinner("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…..."):
                        progress_bar = st.progress(0)
                        self.X, self.y = self.data_loader.download_dataset()
                        
                        # Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…
                        (self.X_train, self.X_val, self.X_test, 
                         self.y_train, self.y_val, self.y_test) = self.data_loader.split_data(self.X, self.y)
                        
                        st.session_state.data_loaded = True
                        st.session_state.X = self.X
                        st.session_state.y = self.y
                        st.session_state.X_train = self.X_train
                        st.session_state.X_val = self.X_val
                        st.session_state.X_test = self.X_test
                        st.session_state.y_train = self.y_train
                        st.session_state.y_val = self.y_val
                        st.session_state.y_test = self.y_test
                        
                        progress_bar.progress(100)
                        st.success(f"âœ… Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ {n_samples} Ð·Ð°Ð¿Ð¸ÑÐµÐ¹!")
            
            else:  # Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ñ„Ð°Ð¹Ð»
                st.subheader("Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ„Ð°Ð¹Ð»Ð°")
                
                uploaded_file = st.file_uploader(
                    "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ñ„Ð°Ð¹Ð» Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð­ÐšÐ“:", 
                    type=['csv', 'txt', 'npy'],
                    help="ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹: CSV, TXT, NPY"
                )
                
                if uploaded_file is not None:
                    try:
                        if uploaded_file.name.endswith('.csv'):
                            data = pd.read_csv(uploaded_file)
                            if len(data.columns) >= 2:
                                self.X = data.iloc[:, :-1].values
                                self.y = data.iloc[:, -1].values
                            else:
                                st.error("CSV Ñ„Ð°Ð¹Ð» Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ 2 ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸")
                                return
                        
                        elif uploaded_file.name.endswith('.txt'):
                            data = np.loadtxt(uploaded_file)
                            if data.ndim == 2:
                                self.X = data[:, :-1]
                                self.y = data[:, -1]
                            else:
                                st.error("TXT Ñ„Ð°Ð¹Ð» Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ 2D Ð¼Ð°ÑÑÐ¸Ð²Ð¾Ð¼")
                                return
                        
                        elif uploaded_file.name.endswith('.npy'):
                            data = np.load(uploaded_file, allow_pickle=True)
                            if isinstance(data, tuple) and len(data) == 2:
                                self.X, self.y = data
                            else:
                                st.error("NPY Ñ„Ð°Ð¹Ð» Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ (X, y)")
                                return
                        
                        # Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…
                        (self.X_train, self.X_val, self.X_test, 
                         self.y_train, self.y_val, self.y_test) = self.data_loader.split_data(self.X, self.y)
                        
                        st.session_state.data_loaded = True
                        st.session_state.X = self.X
                        st.session_state.y = self.y
                        st.session_state.X_train = self.X_train
                        st.session_state.X_val = self.X_val
                        st.session_state.X_test = self.X_test
                        st.session_state.y_train = self.y_train
                        st.session_state.y_val = self.y_val
                        st.session_state.y_test = self.y_test
                        
                        st.success(f"âœ… Ð¤Ð°Ð¹Ð» {uploaded_file.name} ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½!")
                        
                    except Exception as e:
                        st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ñ„Ð°Ð¹Ð»Ð°: {str(e)}")
        
        # ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ ÐµÑÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹
        if st.session_state.get('data_loaded', False):
            self.X = st.session_state.X
            self.y = st.session_state.y
            
            with col2:
                st.subheader("ðŸ“ˆ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°")
                
                stats = {
                    "Ð’ÑÐµÐ³Ð¾ Ð·Ð°Ð¿Ð¸ÑÐµÐ¹": len(self.X),
                    "Ð”Ð»Ð¸Ð½Ð° ÑÐ¸Ð³Ð½Ð°Ð»Ð°": f"{self.X.shape[1]} Ð¾Ñ‚ÑÑ‡ÐµÑ‚Ð¾Ð²",
                    "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ»Ð°ÑÑÐ¾Ð²": len(np.unique(self.y)),
                    "ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°": f"{len(st.session_state.X_train)}",
                    "Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°": f"{len(st.session_state.X_val)}",
                    "Ð¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°": f"{len(st.session_state.X_test)}"
                }
                
                for key, value in stats.items():
                    st.metric(key, value)
            
            # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ¾Ð²
            st.subheader("ðŸ“Š Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ¾Ð²")
            
            class_counts = pd.Series(self.y).value_counts().sort_index()
            class_names = [self.config.ARRHYTHMIA_CLASSES.get(i, f"ÐšÐ»Ð°ÑÑ {i}") 
                          for i in class_counts.index]
            
            # Ð¡Ñ‚Ð¾Ð»Ð±Ñ‡Ð°Ñ‚Ð°Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ð°
            fig_bar = go.Figure(data=[go.Bar(
                x=class_names,
                y=class_counts.values,
                marker_color=['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6']
            )])
            fig_bar.update_layout(
                title="Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼",
                xaxis_title="ÐšÐ»Ð°ÑÑ Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ð¸",
                yaxis_title="ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð·Ð°Ð¿Ð¸ÑÐµÐ¹",
                template="plotly_white"
            )
            st.plotly_chart(fig_bar, use_container_width=True)
            
            # ÐšÑ€ÑƒÐ³Ð¾Ð²Ð°Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ð°
            fig_pie = go.Figure(data=[go.Pie(
                labels=class_names,
                values=class_counts.values,
                hole=.3,
                marker_colors=['#2ecc71', '#3498db', '#e74c3c', '#f39c12', '#9b59b6']
            )])
            fig_pie.update_layout(title="ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚Ð½Ð¾Ðµ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ¾Ð²")
            st.plotly_chart(fig_pie, use_container_width=True)
            
            # ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²
            st.subheader("ðŸ“ˆ ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð² Ð­ÐšÐ“")
            
            selected_class = st.selectbox(
                "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÐºÐ»Ð°ÑÑ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð°:",
                list(self.config.ARRHYTHMIA_CLASSES.items()),
                format_func=lambda x: x[1],
                key="signal_class_select"
            )
            
            if selected_class:
                class_id, class_name = selected_class
                class_indices = np.where(self.y == class_id)[0]
                
                if len(class_indices) > 0:
                    n_examples = min(3, len(class_indices))
                    example_indices = class_indices[:n_examples]
                    
                    fig_signals = make_subplots(
                        rows=n_examples, cols=1,
                        subplot_titles=[f"ÐŸÑ€Ð¸Ð¼ÐµÑ€ {i+1}: {class_name}" 
                                       for i in range(n_examples)]
                    )
                    
                    for i, idx in enumerate(example_indices):
                        fig_signals.add_trace(
                            go.Scatter(
                                y=self.X[idx],
                                mode='lines',
                                name=f"ÐŸÑ€Ð¸Ð¼ÐµÑ€ {i+1}",
                                line=dict(color='blue', width=1.5)
                            ),
                            row=i+1, col=1
                        )
                    
                    fig_signals.update_layout(
                        height=250 * n_examples,
                        showlegend=False,
                        template="plotly_white"
                    )
                    
                    for i in range(n_examples):
                        fig_signals.update_xaxes(title_text="ÐžÑ‚ÑÑ‡ÐµÑ‚Ñ‹", row=i+1, col=1)
                        fig_signals.update_yaxes(title_text="ÐÐ¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ð°", row=i+1, col=1)
                    
                    st.plotly_chart(fig_signals, use_container_width=True)
            
            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²
            if st.checkbox("ðŸ“Š ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²"):
                st.subheader("ðŸ“‹ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²")
                
                # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²ÑƒÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
                feature_stats = pd.DataFrame({
                    'Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ': np.mean(self.X, axis=0),
                    'Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ðµ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ðµ': np.std(self.X, axis=0),
                    'ÐœÐ¸Ð½Ð¸Ð¼ÑƒÐ¼': np.min(self.X, axis=0),
                    'ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼': np.max(self.X, axis=0),
                    'ÐœÐµÐ´Ð¸Ð°Ð½Ð°': np.median(self.X, axis=0)
                })
                
                st.dataframe(feature_stats.describe().round(4), use_container_width=True)
                
                # Ð“Ð¸ÑÑ‚Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÑÑ€ÐµÐ´Ð½Ð¸Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹
                fig_hist = go.Figure(data=[go.Histogram(
                    x=feature_stats['Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ'],
                    nbinsx=50,
                    marker_color='#3498db',
                    opacity=0.7
                )])
                fig_hist.update_layout(
                    title="Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÑ€ÐµÐ´Ð½Ð¸Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²",
                    xaxis_title="Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ",
                    yaxis_title="Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð°",
                    template="plotly_white"
                )
                st.plotly_chart(fig_hist, use_container_width=True)
    
    def render_model_training_tab(self):
        """Ð’ÐºÐ»Ð°Ð´ÐºÐ° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹."""
        st.header("ðŸ¤– ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        if not st.session_state.get('data_loaded', False):
            st.warning("âš ï¸ Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð½Ð° Ð²ÐºÐ»Ð°Ð´ÐºÐµ 'ÐÐ½Ð°Ð»Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…'")
            return
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· session state
        X_train = st.session_state.X_train
        X_val = st.session_state.X_val
        y_train = st.session_state.y_train
        y_val = st.session_state.y_val
        
        # Ð’Ñ‹Ð±Ð¾Ñ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        model_type = st.radio(
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿ Ð¼Ð¾Ð´ÐµÐ»Ð¸:",
            ["Random Forest", "CNN (Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ)", "ÐžÐ±Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸"],
            horizontal=True,
            key="model_type_radio"
        )
        
        if model_type in ["Random Forest", "ÐžÐ±Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸"]:
            self._render_random_forest_training(X_train, X_val, y_train, y_val)
        
        if model_type in ["CNN", "ÐžÐ±Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸"]:
            self._render_cnn_training(X_train, X_val, y_train, y_val)
    
    def _render_random_forest_training(self, X_train, X_val, y_train, y_val):
        """Ð ÐµÐ½Ð´ÐµÑ€Ð¸Ð½Ð³ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Random Forest."""
        st.subheader("ðŸŒ² Random Forest")
        
        with st.expander("âš™ï¸ ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ", expanded=True):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                n_estimators = st.slider(
                    "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´ÐµÑ€ÐµÐ²ÑŒÐµÐ²:", 
                    min_value=50, 
                    max_value=300, 
                    value=100, 
                    step=50,
                    help="Ð§ÐµÐ¼ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð´ÐµÑ€ÐµÐ²ÑŒÐµÐ², Ñ‚ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÐµ Ð¾Ð±Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ, Ð½Ð¾ Ð´Ð¾Ð»ÑŒÑˆÐµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ"
                )
            
            with col2:
                max_depth = st.slider(
                    "ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð³Ð»ÑƒÐ±Ð¸Ð½Ð°:", 
                    min_value=5, 
                    max_value=50, 
                    value=10, 
                    step=5,
                    help="ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÑ‚ Ð³Ð»ÑƒÐ±Ð¸Ð½Ñƒ Ð´ÐµÑ€ÐµÐ²ÑŒÐµÐ² Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ñ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ"
                )
            
            with col3:
                use_cv = st.checkbox(
                    "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÑŽ", 
                    value=False,
                    help="5-ÐºÑ€Ð°Ñ‚Ð½Ð°Ñ ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð¿Ð¾Ð´Ð±Ð¾Ñ€Ð° Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²"
                )
        
        if st.button("ðŸŒ² ÐžÐ±ÑƒÑ‡Ð¸Ñ‚ÑŒ Random Forest", type="primary", key="train_rf_btn"):
            with st.spinner("ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Random Forest..."):
                try:
                    start_time = datetime.now()
                    
                    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
                    from sklearn.ensemble import RandomForestClassifier
                    
                    rf_model = RandomForestClassifier(
                        n_estimators=n_estimators,
                        max_depth=max_depth,
                        random_state=self.config.RANDOM_STATE,
                        n_jobs=-1
                    )
                    
                    if use_cv:
                        from sklearn.model_selection import cross_val_score
                        cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5)
                        st.info(f"ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
                    
                    rf_model.fit(X_train, y_train)
                    
                    # ÐžÑ†ÐµÐ½ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸
                    y_pred = rf_model.predict(X_val)
                    y_pred_proba = rf_model.predict_proba(X_val)
                    
                    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
                    accuracy = accuracy_score(y_val, y_pred)
                    precision = precision_score(y_val, y_pred, average='weighted')
                    recall = recall_score(y_val, y_pred, average='weighted')
                    f1 = f1_score(y_val, y_pred, average='weighted')
                    cm = confusion_matrix(y_val, y_pred)
                    report = classification_report(y_val, y_pred, output_dict=True)
                    
                    training_time = (datetime.now() - start_time).total_seconds()
                    
                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
                    model_filename = f"models/rf_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
                    with open(model_filename, 'wb') as f:
                        pickle.dump(rf_model, f)
                    
                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð² session state
                    st.session_state.rf_model = rf_model
                    st.session_state.rf_metrics = {
                        'accuracy': accuracy,
                        'precision': precision,
                        'recall': recall,
                        'f1_score': f1,
                        'confusion_matrix': cm,
                        'classification_report': report,
                        'training_time': training_time,
                        'model_path': model_filename
                    }
                    st.session_state.models_trained = True
                    
                    # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð² Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²
                    experiment_data = {
                        'timestamp': datetime.now().isoformat(),
                        'model_type': 'Random Forest',
                        'parameters': {
                            'n_estimators': n_estimators,
                            'max_depth': max_depth,
                            'use_cv': use_cv
                        },
                        'metrics': {
                            'accuracy': accuracy,
                            'precision': precision,
                            'recall': recall,
                            'f1_score': f1,
                            'training_time': training_time
                        }
                    }
                    st.session_state.metrics_history.append(experiment_data)
                    
                    st.success(f"âœ… Random Forest Ð¾Ð±ÑƒÑ‡ÐµÐ½ Ð·Ð° {training_time:.2f} ÑÐµÐº!")
                    
                    # ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
                    self._display_training_results(
                        st.session_state.rf_metrics, 
                        "Random Forest",
                        cm
                    )
                    
                except Exception as e:
                    st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Random Forest: {str(e)}")
    
    def _render_cnn_training(self, X_train, X_val, y_train, y_val):
        """Ð ÐµÐ½Ð´ÐµÑ€Ð¸Ð½Ð³ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ CNN."""
        st.subheader("ðŸ§  CNN (Ð¡Ð²ÐµÑ€Ñ‚Ð¾Ñ‡Ð½Ð°Ñ Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ)")
        
        with st.expander("âš™ï¸ ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                epochs = st.slider(
                    "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¿Ð¾Ñ…:", 
                    min_value=10, 
                    max_value=100, 
                    value=30, 
                    step=10,
                    help="ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´Ð¾Ð² Ð¿Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñƒ"
                )
                learning_rate = st.select_slider(
                    "Ð¡ÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ:",
                    options=[0.1, 0.01, 0.001, 0.0001],
                    value=0.001,
                    help="Ð¨Ð°Ð³ Ð³Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚Ð½Ð¾Ð³Ð¾ ÑÐ¿ÑƒÑÐºÐ°"
                )
            
            with col2:
                batch_size = st.slider(
                    "Ð Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð°:", 
                    min_value=16, 
                    max_value=128, 
                    value=32, 
                    step=16,
                    help="ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð² Ð·Ð° Ð¾Ð´Ð½Ñƒ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸ÑŽ"
                )
                use_early_stopping = st.checkbox(
                    "Ð Ð°Ð½Ð½ÑÑ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°", 
                    value=True,
                    help="ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ð¸ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ð¹"
                )
        
        if st.button("ðŸ§  ÐžÐ±ÑƒÑ‡Ð¸Ñ‚ÑŒ CNN", type="primary", key="train_cnn_btn"):
            with st.spinner("ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ CNN... Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð½ÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¼Ð¸Ð½ÑƒÑ‚."):
                try:
                    start_time = datetime.now()
                    
                    # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ TensorFlow/Keras
                    import tensorflow as tf
                    from tensorflow import keras
                    
                    # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ CNN
                    X_train_cnn = X_train.reshape(-1, X_train.shape[1], 1)
                    X_val_cnn = X_val.reshape(-1, X_val.shape[1], 1)
                    
                    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
                    num_classes = len(np.unique(y_train))
                    
                    model = keras.Sequential([
                        keras.layers.Conv1D(32, kernel_size=5, activation='relu', 
                                          input_shape=(X_train.shape[1], 1),
                                          padding='same'),
                        keras.layers.BatchNormalization(),
                        keras.layers.MaxPooling1D(pool_size=2),
                        keras.layers.Dropout(0.3),
                        
                        keras.layers.Conv1D(64, kernel_size=3, activation='relu',
                                          padding='same'),
                        keras.layers.BatchNormalization(),
                        keras.layers.MaxPooling1D(pool_size=2),
                        keras.layers.Dropout(0.3),
                        
                        keras.layers.Conv1D(128, kernel_size=3, activation='relu',
                                          padding='same'),
                        keras.layers.BatchNormalization(),
                        keras.layers.GlobalAveragePooling1D(),
                        keras.layers.Dropout(0.4),
                        
                        keras.layers.Dense(128, activation='relu'),
                        keras.layers.BatchNormalization(),
                        keras.layers.Dropout(0.4),
                        
                        keras.layers.Dense(64, activation='relu'),
                        keras.layers.Dropout(0.3),
                        
                        keras.layers.Dense(num_classes, activation='softmax')
                    ])
                    
                    # ÐšÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ñ
                    model.compile(
                        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
                        loss='sparse_categorical_crossentropy',
                        metrics=['accuracy', 
                                keras.metrics.Precision(name='precision'),
                                keras.metrics.Recall(name='recall')]
                    )
                    
                    # Callbacks
                    callbacks = []
                    if use_early_stopping:
                        callbacks.append(
                            keras.callbacks.EarlyStopping(
                                monitor='val_loss',
                                patience=10,
                                restore_best_weights=True
                            )
                        )
                    
                    # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
                    history = model.fit(
                        X_train_cnn, y_train,
                        validation_data=(X_val_cnn, y_val),
                        epochs=epochs,
                        batch_size=batch_size,
                        callbacks=callbacks,
                        verbose=0
                    )
                    
                    # ÐžÑ†ÐµÐ½ÐºÐ°
                    val_loss, val_accuracy, val_precision, val_recall = model.evaluate(
                        X_val_cnn, y_val, verbose=0
                    )
                    y_pred = np.argmax(model.predict(X_val_cnn, verbose=0), axis=1)
                    y_pred_proba = model.predict(X_val_cnn, verbose=0)
                    
                    # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                    f1 = f1_score(y_val, y_pred, average='weighted')
                    cm = confusion_matrix(y_val, y_pred)
                    report = classification_report(y_val, y_pred, output_dict=True)
                    
                    training_time = (datetime.now() - start_time).total_seconds()
                    
                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
                    model_filename = f"models/cnn_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.h5"
                    model.save(model_filename)
                    
                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
                    history_filename = f"results/cnn_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    with open(history_filename, 'w') as f:
                        json.dump({k: [float(v) for v in vals] 
                                 for k, vals in history.history.items()}, f)
                    
                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð² session state
                    st.session_state.cnn_model = model
                    st.session_state.cnn_history = history.history
                    st.session_state.cnn_metrics = {
                        'accuracy': val_accuracy,
                        'precision': val_precision,
                        'recall': val_recall,
                        'f1_score': f1,
                        'loss': val_loss,
                        'confusion_matrix': cm,
                        'classification_report': report,
                        'training_time': training_time,
                        'model_path': model_filename,
                        'history_path': history_filename
                    }
                    st.session_state.models_trained = True
                    
                    # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð² Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²
                    experiment_data = {
                        'timestamp': datetime.now().isoformat(),
                        'model_type': 'CNN',
                        'parameters': {
                            'epochs': epochs,
                            'batch_size': batch_size,
                            'learning_rate': learning_rate,
                            'use_early_stopping': use_early_stopping
                        },
                        'metrics': {
                            'accuracy': val_accuracy,
                            'precision': val_precision,
                            'recall': val_recall,
                            'f1_score': f1,
                            'training_time': training_time
                        }
                    }
                    st.session_state.metrics_history.append(experiment_data)
                    
                    st.success(f"âœ… CNN Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð° Ð·Ð° {training_time:.2f} ÑÐµÐº!")
                    
                    # ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
                    self._display_training_results(
                        st.session_state.cnn_metrics, 
                        "CNN",
                        cm,
                        history
                    )
                    
                except Exception as e:
                    st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸ CNN: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
    
    def _display_training_results(self, metrics, model_name, confusion_mat, history=None):
        """ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ."""
        st.subheader(f"ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ {model_name}")
        
        # ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ", f"{metrics['accuracy']:.4f}")
        with col2:
            st.metric("Precision", f"{metrics.get('precision', 0):.4f}")
        with col3:
            st.metric("Recall", f"{metrics.get('recall', 0):.4f}")
        with col4:
            st.metric("F1-Score", f"{metrics.get('f1_score', 0):.4f}")
        
        # Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
        st.info(f"â±ï¸ Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ: {metrics.get('training_time', 0):.2f} ÑÐµÐº")
        
        # ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° Ð¾ÑˆÐ¸Ð±Ð¾Ðº
        st.subheader("ðŸ“‹ ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° Ð¾ÑˆÐ¸Ð±Ð¾Ðº")
        
        class_names = list(self.config.ARRHYTHMIA_CLASSES.values())
        
        fig_cm, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(
            confusion_mat,
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names,
            ax=ax
        )
        ax.set_xlabel('ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸', fontsize=12)
        ax.set_ylabel('Ð˜ÑÑ‚Ð¸Ð½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸', fontsize=12)
        ax.set_title(f'ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° Ð¾ÑˆÐ¸Ð±Ð¾Ðº - {model_name}', fontsize=14, fontweight='bold')
        st.pyplot(fig_cm)
        
        # ÐžÑ‚Ñ‡ÐµÑ‚ Ð¾ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
        if 'classification_report' in metrics:
            st.subheader("ðŸ“„ ÐžÑ‚Ñ‡ÐµÑ‚ Ð¾ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸")
            
            report_df = pd.DataFrame(metrics['classification_report']).transpose()
            st.dataframe(report_df.round(4), use_container_width=True)
        
        # Ð“Ñ€Ð°Ñ„Ð¸ÐºÐ¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð»Ñ CNN
        if history and model_name == "CNN":
            st.subheader("ðŸ“ˆ Ð“Ñ€Ð°Ñ„Ð¸ÐºÐ¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ")
            
            fig_history, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
            
            # Ð“Ñ€Ð°Ñ„Ð¸Ðº Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸
            ax1.plot(history.history['accuracy'], label='ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ', linewidth=2)
            ax1.plot(history.history['val_accuracy'], label='Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð°Ñ', linewidth=2)
            ax1.set_title('Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸', fontsize=12, fontweight='bold')
            ax1.set_xlabel('Ð­Ð¿Ð¾Ñ…Ð°', fontsize=10)
            ax1.set_ylabel('Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ', fontsize=10)
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # Ð“Ñ€Ð°Ñ„Ð¸Ðº Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ
            ax2.plot(history.history['loss'], label='ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‰Ð°Ñ', linewidth=2)
            ax2.plot(history.history['val_loss'], label='Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð°Ñ', linewidth=2)
            ax2.set_title('Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ', fontsize=12, fontweight='bold')
            ax2.set_xlabel('Ð­Ð¿Ð¾Ñ…Ð°', fontsize=10)
            ax2.set_ylabel('ÐŸÐ¾Ñ‚ÐµÑ€Ð¸', fontsize=10)
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            st.pyplot(fig_history)
    
    def render_prediction_tab(self):
        """Ð’ÐºÐ»Ð°Ð´ÐºÐ° Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ."""
        st.header("ðŸ” ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ð¹")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
        has_rf = 'rf_model' in st.session_state
        has_cnn = 'cnn_model' in st.session_state
        
        if not (has_rf or has_cnn):
            st.warning("âš ï¸ Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð±ÑƒÑ‡Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð²ÐºÐ»Ð°Ð´ÐºÐµ 'ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹'")
            return
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
        st.subheader("ðŸ“‚ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Random Forest", use_container_width=True, 
                        disabled=not has_rf):
                try:
                    rf_model = st.session_state.rf_model
                    st.session_state.rf_model_loaded = rf_model
                    st.session_state.rf_metrics_display = st.session_state.rf_metrics
                    st.success("âœ… Random Forest Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½!")
                except Exception as e:
                    st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ: {str(e)}")
        
        with col2:
            if st.button("ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ CNN", use_container_width=True, 
                        disabled=not has_cnn):
                try:
                    cnn_model = st.session_state.cnn_model
                    st.session_state.cnn_model_loaded = cnn_model
                    st.session_state.cnn_metrics_display = st.session_state.cnn_metrics
                    st.success("âœ… CNN Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°!")
                except Exception as e:
                    st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ: {str(e)}")
        
        # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        loaded_models = []
        if 'rf_model_loaded' in st.session_state:
            loaded_models.append("ðŸŒ² Random Forest")
        if 'cnn_model_loaded' in st.session_state:
            loaded_models.append("ðŸ§  CNN")
        
        if loaded_models:
            st.info(f"**Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸:** {', '.join(loaded_models)}")
        
        # Ð’Ñ‹Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        st.subheader("ðŸ“Š Ð’Ñ‹Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ")
        
        prediction_method = st.radio(
            "ÐœÐµÑ‚Ð¾Ð´ Ð²Ð²Ð¾Ð´Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…:",
            ["Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð¸Ð· Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸", 
             "Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ð¹ ÑÐ¸Ð³Ð½Ð°Ð»", 
             "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ñ„Ð°Ð¹Ð»"],
            horizontal=True
        )
        
        if prediction_method == "Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð¸Ð· Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸":
            if st.button("ðŸŽ² Ð’Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€", use_container_width=True):
                if 'X_test' in st.session_state:
                    random_idx = np.random.randint(0, len(st.session_state.X_test))
                    test_signal = st.session_state.X_test[random_idx]
                    true_label = st.session_state.y_test[random_idx]
                    
                    st.session_state.current_signal = test_signal
                    st.session_state.true_label = true_label
                    st.session_state.true_class = self.config.ARRHYTHMIA_CLASSES.get(
                        true_label, f"ÐšÐ»Ð°ÑÑ {true_label}"
                    )
                else:
                    st.error("âŒ Ð¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
        
        elif prediction_method == "Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ð¹ ÑÐ¸Ð³Ð½Ð°Ð»":
            arrhythmia_type = st.selectbox(
                "Ð¢Ð¸Ð¿ Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ð¸ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸:",
                list(self.config.ARRHYTHMIA_CLASSES.items()),
                format_func=lambda x: x[1],
                key="generate_signal_select"
            )
            
            if st.button("ðŸŒ€ Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¸Ð³Ð½Ð°Ð»", use_container_width=True):
                t = np.linspace(0, 1, self.config.SEQUENCE_LENGTH)
                base_ecg = 0.5 * np.sin(2 * np.pi * 1 * t)
                
                class_id, class_name = arrhythmia_type
                
                if class_id == 0:  # ÐÐ¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð¸Ñ‚Ð¼
                    test_signal = base_ecg + 0.1 * np.random.normal(size=self.config.SEQUENCE_LENGTH)
                elif class_id == 1:  # ÐÐ¿Ð½Ð¾Ñ
                    test_signal = base_ecg * (0.5 + 0.5 * np.sin(2 * np.pi * 0.1 * t)) + 0.1 * np.random.normal(size=self.config.SEQUENCE_LENGTH)
                elif class_id == 2:  # Ð¤Ð¸Ð±Ñ€Ð¸Ð»Ð»ÑÑ†Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑÐµÑ€Ð´Ð¸Ð¹
                    test_signal = base_ecg + 0.3 * np.random.normal(size=self.config.SEQUENCE_LENGTH) + 0.1 * np.random.normal(size=self.config.SEQUENCE_LENGTH)
                elif class_id == 3:  # Ð¨ÑƒÐ¼
                    test_signal = 0.8 * np.random.normal(size=self.config.SEQUENCE_LENGTH)
                else:  # Ð”Ñ€ÑƒÐ³Ð°Ñ Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ
                    test_signal = base_ecg * (1 + 0.3 * np.sin(2 * np.pi * 2 * t)) + 0.1 * np.random.normal(size=self.config.SEQUENCE_LENGTH)
                
                st.session_state.current_signal = test_signal
                st.session_state.true_label = class_id
                st.session_state.true_class = class_name
        
        else:  # Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ñ„Ð°Ð¹Ð»
            uploaded_file = st.file_uploader(
                "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ñ„Ð°Ð¹Ð» Ñ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð¼ Ð­ÐšÐ“:",
                type=['csv', 'txt', 'npy'],
                help="Ð¡Ð¸Ð³Ð½Ð°Ð» Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ð´Ð½Ð¾Ð¼ÐµÑ€Ð½Ñ‹Ð¼ Ð¼Ð°ÑÑÐ¸Ð²Ð¾Ð¼"
            )
            
            if uploaded_file is not None:
                try:
                    if uploaded_file.name.endswith('.csv'):
                        data = pd.read_csv(uploaded_file)
                        signal = data.iloc[:, 0].values
                    elif uploaded_file.name.endswith('.txt'):
                        signal = np.loadtxt(uploaded_file)
                    elif uploaded_file.name.endswith('.npy'):
                        signal = np.load(uploaded_file)
                    
                    # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¸Ð³Ð½Ð°Ð»Ð°
                    if len(signal) > self.config.SEQUENCE_LENGTH:
                        signal = signal[:self.config.SEQUENCE_LENGTH]
                    elif len(signal) < self.config.SEQUENCE_LENGTH:
                        signal = np.pad(signal, (0, self.config.SEQUENCE_LENGTH - len(signal)))
                    
                    st.session_state.current_signal = signal
                    st.session_state.true_label = None
                    st.session_state.true_class = "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾"
                    
                    st.success("âœ… Ð¤Ð°Ð¹Ð» ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½!")
                    
                except Exception as e:
                    st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ñ„Ð°Ð¹Ð»Ð°: {str(e)}")
        
        # Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ¸Ð³Ð½Ð°Ð»Ð°
        if 'current_signal' in st.session_state:
            current_signal = st.session_state.current_signal
            
            st.subheader("ðŸ“ˆ Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ¸Ð³Ð½Ð°Ð»Ð°")
            
            fig_signal = go.Figure()
            fig_signal.add_trace(go.Scatter(
                y=current_signal,
                mode='lines',
                name='Ð­ÐšÐ“ ÑÐ¸Ð³Ð½Ð°Ð»',
                line=dict(color='#3498db', width=2)
            ))
            
            if 'true_class' in st.session_state:
                true_class = st.session_state.true_class
                fig_signal.update_layout(
                    title=f"Ð­ÐšÐ“ ÑÐ¸Ð³Ð½Ð°Ð» (Ð˜ÑÑ‚Ð¸Ð½Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ: {true_class})",
                    xaxis_title="ÐžÑ‚ÑÑ‡ÐµÑ‚Ñ‹",
                    yaxis_title="ÐÐ¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ð°",
                    template="plotly_white"
                )
            else:
                fig_signal.update_layout(
                    title="Ð­ÐšÐ“ ÑÐ¸Ð³Ð½Ð°Ð»",
                    xaxis_title="ÐžÑ‚ÑÑ‡ÐµÑ‚Ñ‹",
                    yaxis_title="ÐÐ¼Ð¿Ð»Ð¸Ñ‚ÑƒÐ´Ð°",
                    template="plotly_white"
                )
            
            st.plotly_chart(fig_signal, use_container_width=True)
            
            # ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
            st.subheader("ðŸ”® ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ")
            
            selected_models = []
            if 'rf_model_loaded' in st.session_state:
                selected_models.append('Random Forest')
            if 'cnn_model_loaded' in st.session_state:
                selected_models.append('CNN')
            
            if selected_models:
                models_to_use = st.multiselect(
                    "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:",
                    selected_models,
                    default=selected_models
                )
                
                if st.button("ðŸŽ¯ Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·", type="primary", use_container_width=True):
                    results = []
                    
                    for model_name in models_to_use:
                        if model_name == 'Random Forest' and 'rf_model_loaded' in st.session_state:
                            model = st.session_state.rf_model_loaded
                            
                            # ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·
                            signal_reshaped = current_signal.reshape(1, -1)
                            prediction = model.predict(signal_reshaped)[0]
                            probabilities = model.predict_proba(signal_reshaped)[0]
                            
                            results.append({
                                'model': 'Random Forest',
                                'prediction': int(prediction),
                                'class_name': self.config.ARRHYTHMIA_CLASSES.get(prediction, f"ÐšÐ»Ð°ÑÑ {prediction}"),
                                'confidence': float(np.max(probabilities)),
                                'probabilities': probabilities.tolist(),
                                'all_probs': probabilities
                            })
                        
                        elif model_name == 'CNN' and 'cnn_model_loaded' in st.session_state:
                            model = st.session_state.cnn_model_loaded
                            
                            # ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð·
                            signal_reshaped = current_signal.reshape(1, -1, 1)
                            probabilities = model.predict(signal_reshaped, verbose=0)[0]
                            prediction = np.argmax(probabilities)
                            
                            results.append({
                                'model': 'CNN',
                                'prediction': int(prediction),
                                'class_name': self.config.ARRHYTHMIA_CLASSES.get(prediction, f"ÐšÐ»Ð°ÑÑ {prediction}"),
                                'confidence': float(np.max(probabilities)),
                                'probabilities': probabilities.tolist(),
                                'all_probs': probabilities
                            })
                    
                    if results:
                        st.session_state.prediction_results = results
                        
                        # ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
                        st.subheader("ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ")
                        
                        for result in results:
                            with st.container():
                                col1, col2 = st.columns([1, 2])
                                
                                with col1:
                                    color = "ðŸŸ¢" if result['confidence'] > 0.8 else "ðŸŸ¡" if result['confidence'] > 0.6 else "ðŸ”´"
                                    st.metric(
                                        f"**{result['model']}** {color}",
                                        result['class_name'],
                                        f"Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {result['confidence']:.2%}"
                                    )
                                
                                with col2:
                                    # Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÐµÐ¹
                                    prob_df = pd.DataFrame({
                                        'ÐšÐ»Ð°ÑÑ': list(self.config.ARRHYTHMIA_CLASSES.values()),
                                        'Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ': result['all_probs']
                                    })
                                    
                                    fig_prob = go.Figure(data=[go.Bar(
                                        x=prob_df['Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ'],
                                        y=prob_df['ÐšÐ»Ð°ÑÑ'],
                                        orientation='h',
                                        marker_color=['#2ecc71' if p == result['prediction'] else '#95a5a6' 
                                                     for p in range(len(prob_df))],
                                        text=[f"{p:.1%}" for p in prob_df['Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ']],
                                        textposition='auto'
                                    )])
                                    fig_prob.update_layout(
                                        title=f"Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÐµÐ¹",
                                        xaxis_title="Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ",
                                        xaxis_range=[0, 1],
                                        height=300,
                                        template="plotly_white"
                                    )
                                    st.plotly_chart(fig_prob, use_container_width=True)
                        
                        # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹
                        self._generate_recommendations(results)
                        
                        # ÐšÐ½Ð¾Ð¿ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
                        if st.button("ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð°", type="secondary"):
                            self._save_prediction_results(current_signal, results)
            else:
                st.warning("âš ï¸ Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð¾Ð´Ð½Ñƒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ")
    
    def _generate_recommendations(self, results):
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¾Ð²."""
        st.subheader("ðŸ’¡ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸")
        
        recommendations = {
            0: {
                "title": "âœ… ÐÐ¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐµÑ€Ð´ÐµÑ‡Ð½Ñ‹Ð¹ Ñ€Ð¸Ñ‚Ð¼",
                "description": "ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ¸Ð½ÑƒÑÐ¾Ð²Ñ‹Ð¹ Ñ€Ð¸Ñ‚Ð¼. Ð’ÑÐµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸ Ð² Ð¿Ñ€ÐµÐ´ÐµÐ»Ð°Ñ… Ð½Ð¾Ñ€Ð¼Ñ‹.",
                "actions": [
                    "ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°Ð¹Ñ‚Ðµ Ð¿Ð»Ð°Ð½Ð¾Ð²Ð¾Ðµ Ð½Ð°Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸Ðµ",
                    "Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ ÐµÐ¶ÐµÐ³Ð¾Ð´Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¾ÑÐ¼Ð¾Ñ‚Ñ€",
                    "Ð’ÐµÐ´ÐµÐ½Ð¸Ðµ Ð·Ð´Ð¾Ñ€Ð¾Ð²Ð¾Ð³Ð¾ Ð¾Ð±Ñ€Ð°Ð·Ð° Ð¶Ð¸Ð·Ð½Ð¸"
                ],
                "urgency": "ÐÐ¸Ð·ÐºÐ°Ñ",
                "icon": "âœ…"
            },
            1: {
                "title": "âš ï¸ ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ð°Ð¿Ð½Ð¾Ñ ÑÐ½Ð°",
                "description": "ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹, Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð°Ð¿Ð½Ð¾Ñ ÑÐ½Ð°. Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ°.",
                "actions": [
                    "ÐšÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ ÑÐ¾Ð¼Ð½Ð¾Ð»Ð¾Ð³Ð°",
                    "ÐŸÑ€Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»Ð¸ÑÐ¾Ð¼Ð½Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸",
                    "ÐšÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð·Ð° Ð¶Ð¸Ð·Ð½Ð¸ Ð¸ Ð²ÐµÑÐ° Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸"
                ],
                "urgency": "Ð¡Ñ€ÐµÐ´Ð½ÑÑ",
                "icon": "âš ï¸"
            },
            2: {
                "title": "ðŸš¨ Ð¤Ð¸Ð±Ñ€Ð¸Ð»Ð»ÑÑ†Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑÐµÑ€Ð´Ð¸Ð¹",
                "description": "Ð’Ñ‹ÑÐ²Ð»ÐµÐ½Ð° Ñ„Ð¸Ð±Ñ€Ð¸Ð»Ð»ÑÑ†Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑÐµÑ€Ð´Ð¸Ð¹ - ÑÐµÑ€ÑŒÐµÐ·Ð½Ð¾Ðµ Ð½Ð°Ñ€ÑƒÑˆÐµÐ½Ð¸Ðµ ÑÐµÑ€Ð´ÐµÑ‡Ð½Ð¾Ð³Ð¾ Ñ€Ð¸Ñ‚Ð¼Ð°.",
                "actions": [
                    "Ð¡Ð ÐžÐ§ÐÐÐ¯ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ ÐºÐ°Ñ€Ð´Ð¸Ð¾Ð»Ð¾Ð³Ð°",
                    "Ð­ÐšÐ“ Ð¥Ð¾Ð»Ñ‚ÐµÑ€ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð² Ñ‚ÐµÑ‡ÐµÐ½Ð¸Ðµ 24 Ñ‡Ð°ÑÐ¾Ð²",
                    "ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð°Ð½Ñ‚Ð¸ÐºÐ¾Ð°Ð³ÑƒÐ»ÑÐ½Ñ‚Ð½Ð¾Ð¹ Ñ‚ÐµÑ€Ð°Ð¿Ð¸Ð¸ Ð¿Ð¾ Ð¿Ð¾ÐºÐ°Ð·Ð°Ð½Ð¸ÑÐ¼"
                ],
                "urgency": "Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ",
                "icon": "ðŸš¨"
            },
            3: {
                "title": "ðŸ“¢ Ð¡Ð¸Ð³Ð½Ð°Ð» Ñ ÑˆÑƒÐ¼Ð¾Ð¼",
                "description": "Ð¡Ð¸Ð³Ð½Ð°Ð» ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð·Ð½Ð°Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑˆÑƒÐ¼Ñ‹, Ð·Ð°Ñ‚Ñ€ÑƒÐ´Ð½ÑÑŽÑ‰Ð¸Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·.",
                "actions": [
                    "ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ðµ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ Ð­ÐšÐ“",
                    "ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐ»ÐµÐºÑ‚Ñ€Ð¾Ð´Ð¾Ð² Ð¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° ÐºÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð°",
                    "Ð˜ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ð¾Ð² Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ñ"
                ],
                "urgency": "ÐÐ¸Ð·ÐºÐ°Ñ",
                "icon": "ðŸ“¢"
            },
            4: {
                "title": "âš ï¸ Ð”Ñ€ÑƒÐ³Ð°Ñ Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ",
                "description": "ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ Ð½ÐµÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð°. Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¾Ð±ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ.",
                "actions": [
                    "ÐšÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ñ ÐºÐ°Ñ€Ð´Ð¸Ð¾Ð»Ð¾Ð³Ð°",
                    "Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° (Ð­Ñ…Ð¾ÐšÐ“, Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ñ‹Ðµ Ñ‚ÐµÑÑ‚Ñ‹)",
                    "Ð­Ñ…Ð¾ÐºÐ°Ñ€Ð´Ð¸Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€ ÑÐµÑ€Ð´Ñ†Ð°"
                ],
                "urgency": "Ð¡Ñ€ÐµÐ´Ð½ÑÑ",
                "icon": "âš ï¸"
            }
        }
        
        # Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
        for result in results:
            pred_class = result['prediction']
            if pred_class in recommendations:
                rec = recommendations[pred_class]
                
                with st.expander(f"{rec['icon']} {result['model']}: {rec['title']}", 
                               expanded=True):
                    st.markdown(f"**ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ:** {rec['description']}")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown(f"**Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ ÑÑ€Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸:** {rec['urgency']}")
                    with col2:
                        st.markdown(f"**Ð£Ð²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸:** {result['confidence']:.2%}")
                    
                    st.markdown("**Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼Ñ‹Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ:**")
                    for action in rec['actions']:
                        st.markdown(f"â€¢ {action}")
        
        # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¸ÑÑ‚Ð¸Ð½Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ, ÑÑ€Ð°Ð²Ð½Ð¸Ð²Ð°ÐµÐ¼ Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¾Ð¼
        if 'true_label' in st.session_state:
            true_label = st.session_state.true_label
            true_class = self.config.ARRHYTHMIA_CLASSES.get(true_label, f"ÐšÐ»Ð°ÑÑ {true_label}")
            
            st.info(f"**Ð˜ÑÑ‚Ð¸Ð½Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ:** {true_class}")
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¾Ð² Ñ Ð¸ÑÑ‚Ð¸Ð½Ð½Ñ‹Ð¼ ÐºÐ»Ð°ÑÑÐ¾Ð¼
            correct_predictions = []
            for result in results:
                if result['prediction'] == true_label:
                    correct_predictions.append(result['model'])
            
            if correct_predictions:
                st.success(f"âœ… ÐŸÑ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ð»Ð¸: {', '.join(correct_predictions)}")
            else:
                st.warning("âš ï¸ ÐÐ¸ Ð¾Ð´Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ð»Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ")
    
    def _save_prediction_results(self, signal, results):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ."""
        try:
            prediction_data = {
                'timestamp': datetime.now().isoformat(),
                'signal_length': len(signal),
                'true_label': st.session_state.get('true_label', None),
                'true_class': st.session_state.get('true_class', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾'),
                'predictions': results
            }
            
            filename = f"results/prediction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(prediction_data, f, ensure_ascii=False, indent=2, default=str)
            
            st.success(f"âœ… Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² Ñ„Ð°Ð¹Ð»: `{filename}`")
            
        except Exception as e:
            st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ð¸: {str(e)}")
    
    def render_model_comparison_tab(self):
        """Ð’ÐºÐ»Ð°Ð´ÐºÐ° ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹."""
        st.header("ðŸ“ˆ Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
        has_rf = 'rf_metrics' in st.session_state
        has_cnn = 'cnn_metrics' in st.session_state
        
        if not (has_rf or has_cnn):
            st.warning("âš ï¸ Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð±ÑƒÑ‡Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ð²ÐºÐ»Ð°Ð´ÐºÐµ 'ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹'")
            return
        
        # Ð¡Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ
        models_data = {}
        
        if has_rf:
            models_data['Random Forest'] = {
                'metrics': st.session_state.rf_metrics,
                'training_time': st.session_state.rf_metrics.get('training_time', 0),
                'type': 'ÐšÐ»Ð°ÑÑÐ¸Ñ‡ÐµÑÐºÐ°Ñ ML'
            }
        
        if has_cnn:
            models_data['CNN'] = {
                'metrics': st.session_state.cnn_metrics,
                'training_time': st.session_state.cnn_metrics.get('training_time', 0),
                'type': 'ÐÐµÐ¹Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ'
            }
        
        # Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ
        st.subheader("ðŸ“Š Ð¡Ð²Ð¾Ð´Ð½Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº")
        
        comparison_data = []
        for name, data in models_data.items():
            metrics = data['metrics']
            comparison_data.append({
                'ÐœÐ¾Ð´ÐµÐ»ÑŒ': name,
                'Ð¢Ð¸Ð¿': data['type'],
                'Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ': f"{metrics.get('accuracy', 0):.4f}",
                'Precision': f"{metrics.get('precision', 0):.4f}",
                'Recall': f"{metrics.get('recall', 0):.4f}",
                'F1-Score': f"{metrics.get('f1_score', 0):.4f}",
                'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ': f"{data['training_time']:.2f} ÑÐµÐº"
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df.set_index('ÐœÐ¾Ð´ÐµÐ»ÑŒ'), use_container_width=True)
        
        # Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ
        st.subheader("ðŸ“ˆ Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ")
        
        # Ð“Ñ€Ð°Ñ„Ð¸Ðº ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        fig_comparison = go.Figure()
        
        metrics_to_plot = ['Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ', 'Precision', 'Recall', 'F1-Score']
        for metric in metrics_to_plot:
            values = []
            for model_name in models_data.keys():
                metric_key = metric.lower() if metric != 'Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ' else 'accuracy'
                values.append(models_data[model_name]['metrics'].get(metric_key, 0))
            
            fig_comparison.add_trace(go.Bar(
                name=metric,
                x=list(models_data.keys()),
                y=values,
                text=[f"{v:.3f}" for v in values],
                textposition='auto'
            ))
        
        fig_comparison.update_layout(
            title="Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹",
            barmode='group',
            xaxis_title="ÐœÐ¾Ð´ÐµÐ»ÑŒ",
            yaxis_title="Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸",
            yaxis_range=[0, 1],
            template="plotly_white"
        )
        st.plotly_chart(fig_comparison, use_container_width=True)
        
        # Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
        training_times = [data['training_time'] for data in models_data.values()]
        
        fig_time = go.Figure(data=[go.Bar(
            x=list(models_data.keys()),
            y=training_times,
            text=[f"{t:.2f} ÑÐµÐº" for t in training_times],
            textposition='auto',
            marker_color=['#2ecc71', '#3498db']
        )])
        fig_time.update_layout(
            title="Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹",
            xaxis_title="ÐœÐ¾Ð´ÐµÐ»ÑŒ",
            yaxis_title="Ð’Ñ€ÐµÐ¼Ñ (ÑÐµÐº)",
            template="plotly_white"
        )
        st.plotly_chart(fig_time, use_container_width=True)
        
        # ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ñ‹ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
        if has_rf or has_cnn:
            st.subheader("ðŸ” ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ñ‹ Ð¾ÑˆÐ¸Ð±Ð¾Ðº")
            
            n_models = len(models_data)
            fig_cm, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))
            
            if n_models == 1:
                axes = [axes]
            
            class_names = list(self.config.ARRHYTHMIA_CLASSES.values())
            
            for ax, (model_name, model_data) in zip(axes, models_data.items()):
                cm = model_data['metrics'].get('confusion_matrix', np.zeros((5, 5)))
                
                sns.heatmap(
                    cm, 
                    annot=True, 
                    fmt='d', 
                    cmap='Blues',
                    xticklabels=class_names,
                    yticklabels=class_names,
                    ax=ax,
                    cbar=False if n_models > 1 else True
                )
                ax.set_title(f'{model_name}', fontsize=12, fontweight='bold')
                ax.set_xlabel('ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸', fontsize=10)
                ax.set_ylabel('Ð˜ÑÑ‚Ð¸Ð½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸', fontsize=10)
            
            plt.tight_layout()
            st.pyplot(fig_cm)
        
        # Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·
        st.subheader("ðŸ“‹ Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·")
        
        for model_name, model_data in models_data.items():
            with st.expander(f"ðŸ“„ ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚: {model_name}", expanded=False):
                metrics = model_data['metrics']
                
                # ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ", f"{metrics.get('accuracy', 0):.4f}")
                with col2:
                    st.metric("Precision", f"{metrics.get('precision', 0):.4f}")
                with col3:
                    st.metric("Recall", f"{metrics.get('recall', 0):.4f}")
                with col4:
                    st.metric("F1-Score", f"{metrics.get('f1_score', 0):.4f}")
                
                # ÐžÑ‚Ñ‡ÐµÑ‚ Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼
                if 'classification_report' in metrics:
                    st.markdown("**ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¿Ð¾ ÐºÐ»Ð°ÑÑÐ°Ð¼:**")
                    report_df = pd.DataFrame(metrics['classification_report']).transpose()
                    st.dataframe(report_df.round(4), use_container_width=True)
        
        # Ð’Ñ‹Ð²Ð¾Ð´Ñ‹ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
        st.subheader("ðŸŽ¯ Ð’Ñ‹Ð²Ð¾Ð´Ñ‹ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸")
        
        if len(models_data) > 1:
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
            best_model = max(models_data.items(), 
                           key=lambda x: x[1]['metrics'].get('accuracy', 0))
            best_model_name = best_model[0]
            best_accuracy = best_model[1]['metrics'].get('accuracy', 0)
            
            st.info(f"**ðŸ† Ð›ÑƒÑ‡ÑˆÐ°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ:** {best_model_name} Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒÑŽ {best_accuracy:.2%}")
            
            # Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ
            model_names = list(models_data.keys())
            if len(model_names) == 2:
                acc1 = models_data[model_names[0]]['metrics'].get('accuracy', 0)
                acc2 = models_data[model_names[1]]['metrics'].get('accuracy', 0)
                diff = abs(acc1 - acc2)
                
                if diff < 0.05:
                    st.write("âœ… ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÑŽÑ‚ ÑÑ…Ð¾Ð¶ÑƒÑŽ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ.")
                elif diff < 0.1:
                    st.write(f"âš ï¸ Ð—Ð°Ð¼ÐµÑ‚Ð½Ð°Ñ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ð° Ð² Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ ({diff:.2%}).")
                else:
                    st.write(f"ðŸš¨ Ð¡ÑƒÑ‰ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ Ñ€Ð°Ð·Ð½Ð¸Ñ†Ð° Ð² Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ ({diff:.2%}).")
            
            # Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð²Ñ‹Ð±Ð¾Ñ€Ñƒ
            st.markdown("**Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð²Ñ‹Ð±Ð¾Ñ€Ñƒ Ð¼Ð¾Ð´ÐµÐ»Ð¸:**")
            
            recommendations = {
                'Random Forest': [
                    "âœ… Ð‘Ñ‹ÑÑ‚Ñ€Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½Ð° Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…",
                    "âœ… Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð¸Ñ€ÑƒÐµÐ¼Ð¾ÑÑ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²",
                    "âœ… ÐÐµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ GPU Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ",
                    "âš ï¸ ÐœÐ¾Ð¶ÐµÑ‚ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡Ð°Ñ‚ÑŒÑÑ Ð½Ð° ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…",
                    "ðŸ’¡ Ð˜Ð´ÐµÐ°Ð»ÑŒÐ½Ð¾ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ‚Ð¾Ñ‚Ð¸Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸ Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²"
                ],
                'CNN': [
                    "âœ… Ð›ÑƒÑ‡ÑˆÐ°Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð½Ð° ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…",
                    "âœ… ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²",
                    "âœ… Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ñ€ÑÐ´Ð°Ð¼Ð¸",
                    "âš ï¸ Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²",
                    "âš ï¸ Ð¡Ð»Ð¾Ð¶Ð½ÐµÐµ Ð² Ð¸Ð½Ñ‚ÐµÑ€Ð¿Ñ€ÐµÑ‚Ð°Ñ†Ð¸Ð¸",
                    "ðŸ’¡ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ production-ÑÐ¸ÑÑ‚ÐµÐ¼ Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸"
                ]
            }
            
            for model_name, recs in recommendations.items():
                if model_name in models_data:
                    with st.expander(f"ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ {model_name}", expanded=False):
                        for rec in recs:
                            st.write(f"â€¢ {rec}")
        else:
            model_name = list(models_data.keys())[0]
            accuracy = list(models_data.values())[0]['metrics'].get('accuracy', 0)
            st.info(f"âœ… ÐžÐ±ÑƒÑ‡ÐµÐ½Ð° Ð¾Ð´Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ: **{model_name}** Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒÑŽ {accuracy:.2%}")
            
            if accuracy >= 0.85:
                st.success("ðŸŽ‰ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¿Ñ€ÐµÐ²Ñ‹ÑÐ¸Ð»Ð° Ñ†ÐµÐ»ÐµÐ²Ð¾Ð¹ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ (85%)!")
            elif accuracy >= 0.7:
                st.warning("âš ï¸ Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼ (70%).")
            else:
                st.error("âŒ Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð¸Ð¶Ðµ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ð¹.")
    
    def render_experiment_history_tab(self):
        """Ð’ÐºÐ»Ð°Ð´ÐºÐ° Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²."""
        st.header("ðŸ“‹ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²")
        
        if not st.session_state.get('metrics_history', []):
            st.info("â„¹ï¸ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð¿ÑƒÑÑ‚Ð°. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð±ÑƒÑ‡Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸.")
            return
        
        history = st.session_state.metrics_history
        
        # ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ
        st.subheader("ðŸ“Š Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð²")
        
        history_data = []
        for exp in history:
            history_data.append({
                'Ð”Ð°Ñ‚Ð° Ð¸ Ð²Ñ€ÐµÐ¼Ñ': datetime.fromisoformat(exp['timestamp']).strftime('%d.%m.%Y %H:%M'),
                'ÐœÐ¾Ð´ÐµÐ»ÑŒ': exp['model_type'],
                'Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ': f"{exp['metrics']['accuracy']:.4f}",
                'Precision': f"{exp['metrics']['precision']:.4f}",
                'Recall': f"{exp['metrics']['recall']:.4f}",
                'F1-Score': f"{exp['metrics']['f1_score']:.4f}",
                'Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ': f"{exp['metrics']['training_time']:.2f} ÑÐµÐº"
            })
        
        history_df = pd.DataFrame(history_data)
        st.dataframe(history_df, use_container_width=True)
        
        # Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸
        st.subheader("ðŸ“ˆ Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸")
        
        # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ Ñ‚Ð¸Ð¿Ñƒ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        rf_history = [exp for exp in history if exp['model_type'] == 'Random Forest']
        cnn_history = [exp for exp in history if exp['model_type'] == 'CNN']
        
        fig_history = go.Figure()
        
        if rf_history:
            rf_times = [datetime.fromisoformat(exp['timestamp']) for exp in rf_history]
            rf_accuracies = [exp['metrics']['accuracy'] for exp in rf_history]
            
            fig_history.add_trace(go.Scatter(
                x=rf_times,
                y=rf_accuracies,
                mode='lines+markers',
                name='Random Forest',
                line=dict(color='#2ecc71', width=2),
                marker=dict(size=8)
            ))
        
        if cnn_history:
            cnn_times = [datetime.fromisoformat(exp['timestamp']) for exp in cnn_history]
            cnn_accuracies = [exp['metrics']['accuracy'] for exp in cnn_history]
            
            fig_history.add_trace(go.Scatter(
                x=cnn_times,
                y=cnn_accuracies,
                mode='lines+markers',
                name='CNN',
                line=dict(color='#3498db', width=2),
                marker=dict(size=8)
            ))
        
        fig_history.update_layout(
            title="Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹",
            xaxis_title="Ð”Ð°Ñ‚Ð° Ð¸ Ð²Ñ€ÐµÐ¼Ñ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°",
            yaxis_title="Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ",
            yaxis_range=[0, 1],
            template="plotly_white",
            hovermode='x unified'
        )
        st.plotly_chart(fig_history, use_container_width=True)
        
        # Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸
        st.subheader("ðŸ“¤ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ðŸ’¾ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð² JSON", use_container_width=True):
                self._export_history_json(history)
        
        with col2:
            if st.button("ðŸ“Š Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð² CSV", use_container_width=True):
                self._export_history_csv(history_df)
    
    def _export_history_json(self, history):
        """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð² JSON."""
        try:
            filename = f"results/experiment_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2, default=str)
            st.success(f"âœ… Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ð² `{filename}`")
        except Exception as e:
            st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ðµ: {str(e)}")
    
    def _export_history_csv(self, history_df):
        """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð² CSV."""
        try:
            filename = f"results/experiment_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            history_df.to_csv(filename, index=False, encoding='utf-8-sig')
            st.success(f"âœ… Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ð² `{filename}`")
        except Exception as e:
            st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ðµ: {str(e)}")
    
    def render_about_tab(self):
        """Ð’ÐºÐ»Ð°Ð´ÐºÐ° Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ."""
        st.header("â„¹ï¸ Ðž Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            ### ðŸŽ“ Ð”Ð¸Ð¿Ð»Ð¾Ð¼Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚
            
            **Ð¢ÐµÐ¼Ð°:** Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð±Ð¸Ð¾Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
            
            **ÐÐ²Ñ‚Ð¾Ñ€:** Ð§Ð°Ð¹ÐºÐ¸Ð½ Ð’Ð¸Ñ‚Ð°Ð»Ð¸Ð¹ Ð¤ÐµÐ´Ð¾Ñ€Ð¾Ð²Ð¸Ñ‡
            
            **ÐžÐ±Ñ€Ð°Ð·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑƒÑ‡Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ:** Ð§ÐžÐ£Ð’Ðž Â«ÐœÐ¾ÑÐºÐ¾Ð²ÑÐºÐ¸Ð¹ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚ Ð¸Ð¼. Ð¡.Ð®. Ð’Ð¸Ñ‚Ñ‚ÐµÂ»
            
            **Ð¤Ð°ÐºÑƒÐ»ÑŒÑ‚ÐµÑ‚:** Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼ Ð¸ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¹
            
            **ÐÐ°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ¸:** 09.03.02 "Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¸ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¸"
            
            **Ð ÑƒÐºÐ¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ:** ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¼Ð¾Ð»Ð¾Ñ‚Ð¾Ð² ÐÐ½Ð´Ñ€ÐµÐ¹ Ð¡ÐµÑ€Ð³ÐµÐµÐ²Ð¸Ñ‡
            
            **ÐŸÐµÑ€Ð¸Ð¾Ð´ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ:** 10.11.2025 - 07.12.2025
            
            ---
            
            ### ðŸŽ¯ Ð¦ÐµÐ»Ð¸ Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸
            
            **ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ†ÐµÐ»ÑŒ:** Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° 
            ÑÐ»ÐµÐºÑ‚Ñ€Ð¾ÐºÐ°Ñ€Ð´Ð¸Ð¾Ð³Ñ€Ð°Ð¼Ð¼ (Ð­ÐšÐ“) Ð¸ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ ÑÐµÑ€Ð´ÐµÑ‡Ð½Ñ‹Ñ… Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ð¹.
            
            **Ð—Ð°Ð´Ð°Ñ‡Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°:**
            1. Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð² Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð±Ð¸Ð¾Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²
            2. Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð­ÐšÐ“
            3. Ð ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¾Ð² Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ð¹
            4. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð²ÐµÐ±-Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ° Ð´Ð»Ñ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¾Ð¹
            5. ÐžÑ†ÐµÐ½ÐºÐ° ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð¾Ð³Ð¾ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ
            
            ---
            
            ### ðŸ”¬ ÐÐ°ÑƒÑ‡Ð½Ð°Ñ Ð½Ð¾Ð²Ð¸Ð·Ð½Ð°
            
            - ÐŸÑ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ **Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÐµÐ²Ñ‹Ñ… Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð²** Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
            - Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° **Ð³Ð¸Ð±Ñ€Ð¸Ð´Ð½Ð¾Ð¹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹**, ÑÐ¾Ñ‡ÐµÑ‚Ð°ÑŽÑ‰ÐµÐ¹ ÐºÐ»Ð°ÑÑÐ¸Ñ‡ÐµÑÐºÐ¸Ðµ ML Ð¸ Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ðµ ÑÐµÑ‚Ð¸
            - Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ **Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹** Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸
            - Ð ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ **ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¾Ñ†ÐµÐ½ÐºÐ¸** Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
            
            ---
            
            ### ðŸ’¼ ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ð¾ÑÑ‚ÑŒ
            
            **Ð”Ð»Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… ÑƒÑ‡Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ð¹:**
            - ÐŸÐ¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ¸ ÑÐµÑ€Ð´ÐµÑ‡Ð½Ñ‹Ñ… Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ð¹
            - Ð¡Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð­ÐšÐ“ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²
            - ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¸Ñ Ð²Ñ€Ð°Ñ‡ÐµÐ±Ð½Ñ‹Ñ… Ñ€ÐµÑˆÐµÐ½Ð¸Ð¹
            - ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÑƒÑ‚Ð¸Ð½Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡
            
            **Ð”Ð»Ñ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ°:**
            - ÐÐ°Ð³Ð»ÑÐ´Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ ML Ð² Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½Ðµ
            - Ð˜Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð»Ð°Ð±Ð¾Ñ€Ð°Ñ‚Ð¾Ñ€Ð½Ñ‹Ñ… Ñ€Ð°Ð±Ð¾Ñ‚ Ð¸ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹
            - Ð‘Ð°Ð·Ð° Ð´Ð»Ñ Ð´Ð°Ð»ÑŒÐ½ÐµÐ¹ÑˆÐ¸Ñ… Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ñ… Ð¸Ð·Ñ‹ÑÐºÐ°Ð½Ð¸Ð¹
            """)
        
        with col2:
            st.subheader("ðŸ“Š Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸")
            
            tech_specs = [
                ("Ð¯Ð·Ñ‹Ðº Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ", "Python 3.9+"),
                ("ÐžÐ±ÑŠÐµÐ¼ ÐºÐ¾Ð´Ð°", ">2500 ÑÑ‚Ñ€Ð¾Ðº"),
                ("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹", "2 (RF + CNN)"),
                ("ÐšÐ»Ð°ÑÑÐ¾Ð² Ð°Ñ€Ð¸Ñ‚Ð¼Ð¸Ð¹", "5"),
                ("ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ", "85%"),
                ("Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ", "<10 Ð¼Ð¸Ð½ÑƒÑ‚"),
                ("ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹", "CSV, TXT, NPY"),
                ("Ð¢Ñ€ÐµÐ±ÑƒÐµÐ¼Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ", "â‰¥4 Ð“Ð‘ ÐžÐ—Ð£"),
                ("Ð˜Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ", "Web (Streamlit)")
            ]
            
            for spec, value in tech_specs:
                st.metric(spec, value)
            
            st.markdown("---")
            
            st.subheader("ðŸ“š Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ðµ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¸")
            
            technologies = {
                "Streamlit": "Ð’ÐµÐ±-Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ",
                "Scikit-learn": "ÐšÐ»Ð°ÑÑÐ¸Ñ‡ÐµÑÐºÐ¸Ðµ ML Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹",
                "TensorFlow/Keras": "ÐÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ðµ ÑÐµÑ‚Ð¸",
                "Pandas/NumPy": "ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…",
                "Matplotlib/Seaborn": "Ð¡Ñ‚Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ",
                "Plotly": "Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ",
                "SciPy": "ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²"
            }
            
            for tech, desc in technologies.items():
                st.markdown(f"**{tech}** - {desc}")
            
            st.markdown("---")
            
            st.subheader("ðŸ“ Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°")
            
            structure = """
            ðŸ“¦ ecg-analysis-system/
            â”œâ”€â”€ ðŸ“ app/
            â”‚   â”œâ”€â”€ ðŸ“ core/          # ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÑƒÐ»Ð¸
            â”‚   â”‚   â”œâ”€â”€ data_loader.py
            â”‚   â”‚   â”œâ”€â”€ feature_engineer.py
            â”‚   â”‚   â””â”€â”€ model_loader.py
            â”‚   â”œâ”€â”€ ðŸ“ services/      # Ð¡ÐµÑ€Ð²Ð¸ÑÐ½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸
            â”‚   â”‚   â”œâ”€â”€ training_service.py
            â”‚   â”‚   â””â”€â”€ prediction_service.py
            â”‚   â””â”€â”€ ðŸ“ web/           # Ð’ÐµÐ±-Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ
            â”‚       â””â”€â”€ ui.py
            â”œâ”€â”€ ðŸ“ models/            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
            â”œâ”€â”€ ðŸ“ data/              # ÐÐ°Ð±Ð¾Ñ€Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
            â”œâ”€â”€ ðŸ“ results/           # Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
            â”œâ”€â”€ ðŸ“„ main.py            # Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
            â”œâ”€â”€ ðŸ“„ requirements.txt   # Ð—Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸
            â””â”€â”€ ðŸ“„ README.md          # Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ
            """
            
            st.code(structure, language="text")
        
        st.markdown("---")
        
        st.subheader("ðŸ“ž ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹")
        
        contact_col1, contact_col2 = st.columns(2)
        
        with contact_col1:
            st.markdown("""
            **ðŸ“§ Ð­Ð»ÐµÐºÑ‚Ñ€Ð¾Ð½Ð½Ð°Ñ Ð¿Ð¾Ñ‡Ñ‚Ð°:**
            - vit.chaykin@example.com
            - project.ecg@example.com
            
            **ðŸŒ ÐžÐ½Ð»Ð°Ð¹Ð½-Ñ€ÐµÑÑƒÑ€ÑÑ‹:**
            - [GitHub Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¹](https://github.com/username/ecg-analysis)
            - [LinkedIn Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ](https://linkedin.com/in/username)
            """)
        
        with contact_col2:
            st.markdown("""
            **ðŸ“± ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ:**
            - Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (XXX) XXX-XX-XX
            - Ð Ð°Ð±Ð¾Ñ‡Ð¸Ðµ Ñ‡Ð°ÑÑ‹: 9:00-18:00 (ÐœÐ¡Ðš)
            - ÐŸÑ€Ð¸ÐµÐ¼Ð½Ñ‹Ðµ Ð´Ð½Ð¸: ÐŸÐ½-ÐŸÑ‚
            
            **ðŸ¢ ÐžÐ±Ñ€Ð°Ð·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑƒÑ‡Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ:**
            Ð§ÐžÐ£Ð’Ðž Â«ÐœÐ£ Ð¸Ð¼. Ð¡.Ð®. Ð’Ð¸Ñ‚Ñ‚ÐµÂ»
            ÐœÐ¾ÑÐºÐ²Ð°, 2-Ð¹ ÐšÐ¾Ð¶ÑƒÑ…Ð¾Ð²ÑÐºÐ¸Ð¹ Ð¿Ñ€., Ð´. 12
            """)
        
        # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð»Ð¸Ñ†ÐµÐ½Ð·Ð¸Ð¸
        with st.expander("ðŸ“„ Ð›Ð¸Ñ†ÐµÐ½Ð·Ð¸Ð¾Ð½Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ", expanded=False):
            st.markdown("""
            ### MIT License
            
            Copyright Â© 2025 Ð§Ð°Ð¹ÐºÐ¸Ð½ Ð’Ð¸Ñ‚Ð°Ð»Ð¸Ð¹ Ð¤ÐµÐ´Ð¾Ñ€Ð¾Ð²Ð¸Ñ‡
            
            Ð”Ð°Ð½Ð½Ð¾Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð½Ð¾Ðµ Ð¾Ð±ÐµÑÐ¿ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ÑÑ Â«ÐšÐÐš Ð•Ð¡Ð¢Ð¬Â», Ð±ÐµÐ· ÐºÐ°ÐºÐ¸Ñ…-Ð»Ð¸Ð±Ð¾ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¹.
            
            **Ð Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¾:**
            - Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² ÐºÐ¾Ð¼Ð¼ÐµÑ€Ñ‡ÐµÑÐºÐ¸Ñ… Ð¸ Ð½ÐµÐºÐ¾Ð¼Ð¼ÐµÑ€Ñ‡ÐµÑÐºÐ¸Ñ… Ñ†ÐµÐ»ÑÑ…
            - ÐœÐ¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð¸ Ñ€Ð°ÑÐ¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ
            - Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Ñ‡Ð°ÑÑ‚Ð½Ñ‹Ñ… Ð¸ ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°Ñ…
            
            **Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ:**
            - Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾Ð± Ð°Ð²Ñ‚Ð¾Ñ€ÑÐºÐ¾Ð¼ Ð¿Ñ€Ð°Ð²Ðµ
            - Ð£ÐºÐ°Ð·Ð°Ð½Ð¸Ðµ ÑÑÑ‹Ð»ÐºÐ¸ Ð½Ð° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚
            
            **Ð—Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½Ð¾:**
            - Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… Ñ†ÐµÐ»ÑÑ… Ð±ÐµÐ· Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
            - ÐžÑ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð°Ð²Ñ‚Ð¾Ñ€Ð° Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´ÑÑ‚Ð²Ð¸Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
            
            **Ð’Ð°Ð¶Ð½Ð¾Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ:**
            Ð”Ð°Ð½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° ÑÐ²Ð»ÑÐµÑ‚ÑÑ ÑƒÑ‡ÐµÐ±Ð½Ñ‹Ð¼ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð¼ Ð¸ Ð½Ðµ Ð¿Ñ€ÐµÐ´Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð° 
            Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¾Ð¹ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐµ.
            """)
    
    def export_results(self):
        """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð²ÑÐµÑ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²."""
        try:
            export_data = {
                'timestamp': datetime.now().isoformat(),
                'project': 'ECG Analysis System',
                'author': 'Ð§Ð°Ð¹ÐºÐ¸Ð½ Ð’Ð¸Ñ‚Ð°Ð»Ð¸Ð¹ Ð¤ÐµÐ´Ð¾Ñ€Ð¾Ð²Ð¸Ñ‡',
                'models': {},
                'experiments': st.session_state.get('metrics_history', []),
                'predictions': st.session_state.get('prediction_results', [])
            }
            
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑÑ…
            if 'rf_metrics' in st.session_state:
                export_data['models']['random_forest'] = {
                    'metrics': st.session_state.rf_metrics,
                    'path': st.session_state.rf_metrics.get('model_path', '')
                }
            
            if 'cnn_metrics' in st.session_state:
                export_data['models']['cnn'] = {
                    'metrics': st.session_state.cnn_metrics,
                    'path': st.session_state.cnn_metrics.get('model_path', '')
                }
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ
            filename = f"results/full_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
            
            st.success(f"âœ… Ð’ÑÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð² `{filename}`")
            
        except Exception as e:
            st.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ðµ: {str(e)}")
    
    def run(self):
        """Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ."""
        self.render_sidebar()
        
        current_tab = st.session_state.current_tab
        
        tab_functions = {
            "data_analysis": self.render_data_analysis_tab,
            "model_training": self.render_model_training_tab,
            "prediction": self.render_prediction_tab,
            "model_comparison": self.render_model_comparison_tab,
            "experiment_history": self.render_experiment_history_tab,
            "about": self.render_about_tab
        }
        
        if current_tab in tab_functions:
            tab_functions[current_tab]()
        else:
            st.error(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð²ÐºÐ»Ð°Ð´ÐºÐ°: {current_tab}")

def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ."""
    app = BiomedicalApp()
    app.run()

if __name__ == "__main__":
    main()